[2025-03-21T20:31:28.615+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: external_customer_pipeline.store_customer_data_to_hdfs_and_hive manual__2025-03-21T20:31:00.249950+00:00 [queued]>
[2025-03-21T20:31:28.631+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: external_customer_pipeline.store_customer_data_to_hdfs_and_hive manual__2025-03-21T20:31:00.249950+00:00 [queued]>
[2025-03-21T20:31:28.632+0000] {taskinstance.py:1359} INFO - Starting attempt 1 of 3
[2025-03-21T20:31:28.654+0000] {taskinstance.py:1380} INFO - Executing <Task(PythonOperator): store_customer_data_to_hdfs_and_hive> on 2025-03-21 20:31:00.249950+00:00
[2025-03-21T20:31:28.667+0000] {standard_task_runner.py:57} INFO - Started process 2545 to run task
[2025-03-21T20:31:28.672+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'external_customer_pipeline', 'store_customer_data_to_hdfs_and_hive', 'manual__2025-03-21T20:31:00.249950+00:00', '--job-id', '914', '--raw', '--subdir', 'DAGS_FOLDER/pipeline_batch.py', '--cfg-path', '/tmp/tmpzb3kihps']
[2025-03-21T20:31:28.677+0000] {standard_task_runner.py:85} INFO - Job 914: Subtask store_customer_data_to_hdfs_and_hive
[2025-03-21T20:31:28.741+0000] {task_command.py:415} INFO - Running <TaskInstance: external_customer_pipeline.store_customer_data_to_hdfs_and_hive manual__2025-03-21T20:31:00.249950+00:00 [running]> on host 4f421949e8a6
[2025-03-21T20:31:28.888+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='external_customer_pipeline' AIRFLOW_CTX_TASK_ID='store_customer_data_to_hdfs_and_hive' AIRFLOW_CTX_EXECUTION_DATE='2025-03-21T20:31:00.249950+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-03-21T20:31:00.249950+00:00'
[2025-03-21T20:31:34.153+0000] {pipeline_batch.py:233} INFO - HDFS put command output: 
[2025-03-21T20:31:37.800+0000] {pipeline_batch.py:266} ERROR - Hive command failed: SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/hive/lib/log4j-slf4j-impl-2.17.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Connecting to jdbc:hive2://localhost:10000
Connected to: Apache Hive (version 3.1.3)
Driver: Hive JDBC (version 3.1.3)
Transaction isolation: TRANSACTION_REPEATABLE_READ
INFO  : Compiling command(queryId=root_20250321203137_816f15ac-9c48-44a2-ac01-746957062388): CREATE EXTERNAL TABLE IF NOT EXISTS customers (
                customer_id STRING,
                account_history ARRAY<STRING>,
                demographics STRUCT<age: INT, location: STRING>,
                behavioral_patterns STRUCT<avg_transaction_value: DOUBLE>
            )
            PARTITIONED BY (batch_id STRING)
            ROW FORMAT SERDE 'org.apache.hive.hcatalog.data.JsonSerDe'
            STORED AS TEXTFILE
            LOCATION '/data/customer'
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Semantic Analysis Completed (retrial = false)
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=root_20250321203137_816f15ac-9c48-44a2-ac01-746957062388); Time taken: 0.029 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=root_20250321203137_816f15ac-9c48-44a2-ac01-746957062388): CREATE EXTERNAL TABLE IF NOT EXISTS customers (
                customer_id STRING,
                account_history ARRAY<STRING>,
                demographics STRUCT<age: INT, location: STRING>,
                behavioral_patterns STRUCT<avg_transaction_value: DOUBLE>
            )
            PARTITIONED BY (batch_id STRING)
            ROW FORMAT SERDE 'org.apache.hive.hcatalog.data.JsonSerDe'
            STORED AS TEXTFILE
            LOCATION '/data/customer'
INFO  : Completed executing command(queryId=root_20250321203137_816f15ac-9c48-44a2-ac01-746957062388); Time taken: 0.001 seconds
INFO  : OK
INFO  : Concurrency mode is disabled, not creating a lock manager
No rows affected (0.125 seconds)
INFO  : Compiling command(queryId=root_20250321203137_475d9eff-781f-4ca4-aa18-27f918ddbe05): ALTER TABLE customers ADD IF NOT EXISTS PARTITION (batch_id='20250321_203100') LOCATION '/data/customer/customer_20250321_203100.json'
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Semantic Analysis Completed (retrial = false)
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=root_20250321203137_475d9eff-781f-4ca4-aa18-27f918ddbe05); Time taken: 0.025 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=root_20250321203137_475d9eff-781f-4ca4-aa18-27f918ddbe05): ALTER TABLE customers ADD IF NOT EXISTS PARTITION (batch_id='20250321_203100') LOCATION '/data/customer/customer_20250321_203100.json'
INFO  : Starting task [Stage-0:DDL] in serial mode
ERROR : FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. MetaException(message:java.io.IOException: Got exception: org.apache.hadoop.fs.FileAlreadyExistsException Path is not a directory: /data/customer/customer_20250321_203100.json
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:54)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3132)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:1126)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:705)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:869)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:815)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2675)
)
INFO  : Completed executing command(queryId=root_20250321203137_475d9eff-781f-4ca4-aa18-27f918ddbe05); Time taken: 0.057 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
Error: Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. MetaException(message:java.io.IOException: Got exception: org.apache.hadoop.fs.FileAlreadyExistsException Path is not a directory: /data/customer/customer_20250321_203100.json
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:54)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3132)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:1126)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:705)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:869)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:815)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2675)
) (state=08S01,code=1)
Closing: 0: jdbc:hive2://localhost:10000

[2025-03-21T20:31:38.114+0000] {pipeline_batch.py:42} ERROR - Failed to send Discord message: 400 - {"embeds": ["0"]}
[2025-03-21T20:31:38.121+0000] {taskinstance.py:1935} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/opt/airflow/dags/pipeline_batch.py", line 256, in store_customer_data_to_hdfs_and_hive
    result = subprocess.run(
  File "/usr/local/lib/python3.8/subprocess.py", line 516, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '
            docker exec hive beeline -u "jdbc:hive2://localhost:10000" --hiveconf hive.exec.dynamic.partition.mode=nonstrict -e "
            CREATE EXTERNAL TABLE IF NOT EXISTS customers (
                customer_id STRING,
                account_history ARRAY<STRING>,
                demographics STRUCT<age: INT, location: STRING>,
                behavioral_patterns STRUCT<avg_transaction_value: DOUBLE>
            )
            PARTITIONED BY (batch_id STRING)
            ROW FORMAT SERDE 'org.apache.hive.hcatalog.data.JsonSerDe'
            STORED AS TEXTFILE
            LOCATION '/data/customer';
            ALTER TABLE customers ADD IF NOT EXISTS PARTITION (batch_id='20250321_203100') LOCATION '/data/customer/customer_20250321_203100.json';
            "
            ' returned non-zero exit status 1.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 192, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 209, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/pipeline_batch.py", line 267, in store_customer_data_to_hdfs_and_hive
    raise RuntimeError(error_message)
RuntimeError: Hive command failed: SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/hive/lib/log4j-slf4j-impl-2.17.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Connecting to jdbc:hive2://localhost:10000
Connected to: Apache Hive (version 3.1.3)
Driver: Hive JDBC (version 3.1.3)
Transaction isolation: TRANSACTION_REPEATABLE_READ
INFO  : Compiling command(queryId=root_20250321203137_816f15ac-9c48-44a2-ac01-746957062388): CREATE EXTERNAL TABLE IF NOT EXISTS customers (
                customer_id STRING,
                account_history ARRAY<STRING>,
                demographics STRUCT<age: INT, location: STRING>,
                behavioral_patterns STRUCT<avg_transaction_value: DOUBLE>
            )
            PARTITIONED BY (batch_id STRING)
            ROW FORMAT SERDE 'org.apache.hive.hcatalog.data.JsonSerDe'
            STORED AS TEXTFILE
            LOCATION '/data/customer'
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Semantic Analysis Completed (retrial = false)
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=root_20250321203137_816f15ac-9c48-44a2-ac01-746957062388); Time taken: 0.029 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=root_20250321203137_816f15ac-9c48-44a2-ac01-746957062388): CREATE EXTERNAL TABLE IF NOT EXISTS customers (
                customer_id STRING,
                account_history ARRAY<STRING>,
                demographics STRUCT<age: INT, location: STRING>,
                behavioral_patterns STRUCT<avg_transaction_value: DOUBLE>
            )
            PARTITIONED BY (batch_id STRING)
            ROW FORMAT SERDE 'org.apache.hive.hcatalog.data.JsonSerDe'
            STORED AS TEXTFILE
            LOCATION '/data/customer'
INFO  : Completed executing command(queryId=root_20250321203137_816f15ac-9c48-44a2-ac01-746957062388); Time taken: 0.001 seconds
INFO  : OK
INFO  : Concurrency mode is disabled, not creating a lock manager
No rows affected (0.125 seconds)
INFO  : Compiling command(queryId=root_20250321203137_475d9eff-781f-4ca4-aa18-27f918ddbe05): ALTER TABLE customers ADD IF NOT EXISTS PARTITION (batch_id='20250321_203100') LOCATION '/data/customer/customer_20250321_203100.json'
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Semantic Analysis Completed (retrial = false)
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=root_20250321203137_475d9eff-781f-4ca4-aa18-27f918ddbe05); Time taken: 0.025 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=root_20250321203137_475d9eff-781f-4ca4-aa18-27f918ddbe05): ALTER TABLE customers ADD IF NOT EXISTS PARTITION (batch_id='20250321_203100') LOCATION '/data/customer/customer_20250321_203100.json'
INFO  : Starting task [Stage-0:DDL] in serial mode
ERROR : FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. MetaException(message:java.io.IOException: Got exception: org.apache.hadoop.fs.FileAlreadyExistsException Path is not a directory: /data/customer/customer_20250321_203100.json
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:54)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3132)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:1126)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:705)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:869)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:815)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2675)
)
INFO  : Completed executing command(queryId=root_20250321203137_475d9eff-781f-4ca4-aa18-27f918ddbe05); Time taken: 0.057 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
Error: Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. MetaException(message:java.io.IOException: Got exception: org.apache.hadoop.fs.FileAlreadyExistsException Path is not a directory: /data/customer/customer_20250321_203100.json
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:54)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3132)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:1126)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:705)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:869)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:815)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2675)
) (state=08S01,code=1)
Closing: 0: jdbc:hive2://localhost:10000

[2025-03-21T20:31:38.183+0000] {taskinstance.py:1398} INFO - Marking task as UP_FOR_RETRY. dag_id=external_customer_pipeline, task_id=store_customer_data_to_hdfs_and_hive, execution_date=20250321T203100, start_date=20250321T203128, end_date=20250321T203138
[2025-03-21T20:31:38.204+0000] {standard_task_runner.py:104} ERROR - Failed to execute job 914 for task store_customer_data_to_hdfs_and_hive (Hive command failed: SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/hive/lib/log4j-slf4j-impl-2.17.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Connecting to jdbc:hive2://localhost:10000
Connected to: Apache Hive (version 3.1.3)
Driver: Hive JDBC (version 3.1.3)
Transaction isolation: TRANSACTION_REPEATABLE_READ
INFO  : Compiling command(queryId=root_20250321203137_816f15ac-9c48-44a2-ac01-746957062388): CREATE EXTERNAL TABLE IF NOT EXISTS customers (
                customer_id STRING,
                account_history ARRAY<STRING>,
                demographics STRUCT<age: INT, location: STRING>,
                behavioral_patterns STRUCT<avg_transaction_value: DOUBLE>
            )
            PARTITIONED BY (batch_id STRING)
            ROW FORMAT SERDE 'org.apache.hive.hcatalog.data.JsonSerDe'
            STORED AS TEXTFILE
            LOCATION '/data/customer'
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Semantic Analysis Completed (retrial = false)
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=root_20250321203137_816f15ac-9c48-44a2-ac01-746957062388); Time taken: 0.029 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=root_20250321203137_816f15ac-9c48-44a2-ac01-746957062388): CREATE EXTERNAL TABLE IF NOT EXISTS customers (
                customer_id STRING,
                account_history ARRAY<STRING>,
                demographics STRUCT<age: INT, location: STRING>,
                behavioral_patterns STRUCT<avg_transaction_value: DOUBLE>
            )
            PARTITIONED BY (batch_id STRING)
            ROW FORMAT SERDE 'org.apache.hive.hcatalog.data.JsonSerDe'
            STORED AS TEXTFILE
            LOCATION '/data/customer'
INFO  : Completed executing command(queryId=root_20250321203137_816f15ac-9c48-44a2-ac01-746957062388); Time taken: 0.001 seconds
INFO  : OK
INFO  : Concurrency mode is disabled, not creating a lock manager
No rows affected (0.125 seconds)
INFO  : Compiling command(queryId=root_20250321203137_475d9eff-781f-4ca4-aa18-27f918ddbe05): ALTER TABLE customers ADD IF NOT EXISTS PARTITION (batch_id='20250321_203100') LOCATION '/data/customer/customer_20250321_203100.json'
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Semantic Analysis Completed (retrial = false)
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=root_20250321203137_475d9eff-781f-4ca4-aa18-27f918ddbe05); Time taken: 0.025 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=root_20250321203137_475d9eff-781f-4ca4-aa18-27f918ddbe05): ALTER TABLE customers ADD IF NOT EXISTS PARTITION (batch_id='20250321_203100') LOCATION '/data/customer/customer_20250321_203100.json'
INFO  : Starting task [Stage-0:DDL] in serial mode
ERROR : FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. MetaException(message:java.io.IOException: Got exception: org.apache.hadoop.fs.FileAlreadyExistsException Path is not a directory: /data/customer/customer_20250321_203100.json
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:54)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3132)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:1126)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:705)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:869)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:815)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2675)
)
INFO  : Completed executing command(queryId=root_20250321203137_475d9eff-781f-4ca4-aa18-27f918ddbe05); Time taken: 0.057 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
Error: Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. MetaException(message:java.io.IOException: Got exception: org.apache.hadoop.fs.FileAlreadyExistsException Path is not a directory: /data/customer/customer_20250321_203100.json
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:54)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3132)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:1126)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:705)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:869)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:815)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2675)
) (state=08S01,code=1)
Closing: 0: jdbc:hive2://localhost:10000
; 2545)
[2025-03-21T20:31:38.254+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 1
[2025-03-21T20:31:38.283+0000] {taskinstance.py:2776} INFO - 0 downstream tasks scheduled from follow-on schedule check
